{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python_LinkPrediction_TensorFactorization_Vechgrad_optimized_lean.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EUJQbcc0pgWC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5866tRNXcB8"
      },
      "source": [
        "# Link Prediction with Tensor Factorization (VecHGrad method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWX8COPJBSFC"
      },
      "source": [
        "*Last edited: 2021-01-01*\n",
        "\n",
        "### Based on work from\n",
        "\n",
        "Gao, Sheng, Ludovic Denoyer, and Patrick Gallinari. \"Link pattern prediction with tensor decomposition in multi-relational networks.\" In 2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM), pp. 333-340. IEEE, 2011.\n",
        "\n",
        "*Improvements in tensor decomposition from:*\n",
        "\n",
        "VecHGrad: https://arxiv.org/abs/1905.12413\n",
        "\n",
        "VecHGrad Code: https://github.com/dagrate/vechgrad\n",
        "\n",
        "### Data\n",
        "\n",
        "* bowling-green.american-assembly from https://github.com/pol-is/openData\n",
        "  * Filled in with 0 for missing data\n",
        "  * Split in two matrices, one with positive observations (1) and one with negative observations (-1).\n",
        "\n",
        "### How to use\n",
        "\n",
        "* Matrices with pos-neg layer data need to be uploaded to Google Colab\n",
        "* Vector *a* (line 6 below) needs to be updated with dimensions of input data\n",
        "  * Can also be extracted by the csv files themselves\n",
        "* Run helper function cells and main program\n",
        "* Resulting latent feature matrices A, B and C are the ones that minimize the weighted least squares error for the missing data.\n",
        "\n",
        "### Technical details\n",
        "\n",
        "* This notebook uses the [TensorLy](http://tensorly.org/stable/index.html) Python module for tensor representation.\n",
        "* TensorLy supports all of NumPy, Pytorch and Tensorflow as backends (among others), and the notebook is written in a way that supports all three.\n",
        "  * Just change the backend in the `tl.set_backend('pytorch')` line.\n",
        "* Runtime can be changed to GPU or TPU through the menu option *Runtime -> Change runtime type*. (Currently set to *None*)\n",
        "* Some quick performance comparisons (nr_of_iter=1000, random.seed=2320) :\n",
        "  * NumPy: 161.222 s (None)\n",
        "  * PyTorch: 13.9823 s (None), 4.65814 s (GPU), 5.08854 s (TPU)\n",
        "  * TensorFlow: 16.4367 s (None), 2.8769 s (GPU), 13.6554 s (TPU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUJQbcc0pgWC"
      },
      "source": [
        "## Notebook initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag922ezMyoLU",
        "outputId": "15a09c93-a907-43aa-ffa9-b7b18fe1149c"
      },
      "source": [
        "!pip install tensorly\r\n",
        "import numpy as np\r\n",
        "import tensorly as tl\r\n",
        "!pip install line_profiler\r\n",
        "%load_ext line_profiler"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorly in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorly) (1.19.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tensorly) (1.4.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from tensorly) (1.3.7)\n",
            "Requirement already satisfied: line_profiler in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from line_profiler) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->line_profiler) (4.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython->line_profiler) (51.0.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->line_profiler) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->line_profiler) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->line_profiler) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->line_profiler) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->line_profiler) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->line_profiler) (4.8.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->line_profiler) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->line_profiler) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->line_profiler) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->line_profiler) (0.6.0)\n",
            "The line_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext line_profiler\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NTOzLBPZx2d"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UF8gUzt1arh"
      },
      "source": [
        "### TNSRUTILS.JI FUNCTIONS\n",
        "\n",
        "# Weighted least squares error\n",
        "def objfunweighted(X, Xh, Wt):\n",
        "  # Objective function for Least Square Error for any backend \n",
        "  return tl.backend.sqrt(tl.backend.sum((Wt * X - Wt * Xh) ** 2))\n",
        "\n",
        "### ALSCP.JI FUNCTION\n",
        "\n",
        "def nncpals(X, rankR, A, B, C, Weights, maxiter=1000, epsobjfun=1.0E-3):\n",
        "    cp_weights = tl.tensor(np.array([1., 1.])) # Weights needed for rebuilding X from A,B,C\n",
        "\n",
        "    if len(X.shape) > 3:\n",
        "        return println(\"Only third order parafac implemented\") ;\n",
        "\n",
        "    # initialization with supplied random values\n",
        "    Xh = tl.cp_to_tensor((cp_weights,[A,B,C]))  #Equiv in Tensorly\n",
        "\n",
        "    # non-negative CP ALS iterative process\n",
        "    i = 1 ;\n",
        "    while i <= maxiter:\n",
        "        for mode in range(len(X.shape)):\n",
        "\n",
        "            # Hadamard product on all mode != n\n",
        "            V = tl.ones((rankR, rankR)) ;\n",
        "            for n in range(len(X.shape)):\n",
        "              if n != mode:\n",
        "                if n == 0:\n",
        "                  tmpV = A ;\n",
        "                elif n == 1:\n",
        "                  tmpV = B ;\n",
        "                elif n == 2:\n",
        "                  tmpV = C ;\n",
        "                V = V * (tl.transpose(tmpV) @ tmpV) ;\n",
        "\n",
        "            # Khatri-Rao product on all mode != n\n",
        "            if mode == 0:\n",
        "              W = tl.kr((C, B)) ;\n",
        "            elif mode == 1:\n",
        "              W = tl.kr((C, A)) ;\n",
        "            elif mode == 2:\n",
        "              W = tl.kr((B, A)) ;\n",
        "\n",
        "            # non negative update\n",
        "            num = (tl.unfold(X, mode) @ W) + 1.0E-9 ;\n",
        "            if mode == 0:\n",
        "              denum = (A @ (tl.transpose(W) @ W)) + 1.0E-9 ;\n",
        "              A = A * (num / denum);\n",
        "            elif mode == 1:\n",
        "              denum = (B @ (tl.transpose(W) @ W)) + 1.0E-9 ;\n",
        "              B = B * (num / denum);\n",
        "            elif mode == 2:\n",
        "              denum = (C @ (tl.transpose(W) @ W)) + 1.0E-9 ;\n",
        "              C = C * (num / denum);\n",
        "\n",
        "        # calculation evolution\n",
        "        Xh = tl.cp_to_tensor((cp_weights,[A,B,C]))  #Equiv in Tensorly\n",
        "        curvo = objfunweighted(X,Xh,Weights) ;\n",
        "        if curvo > epsobjfun:\n",
        "          i += 1 ;\n",
        "        else:\n",
        "          i = maxiter + 1 ;\n",
        "  \n",
        "    print(\"Number of iterations: \" + str(i-1)) ;\n",
        "    Xh = tl.cp_to_tensor((cp_weights,[A,B,C]))  #Equiv in Tensorly\n",
        "\n",
        "    return A, B, C ;"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4sAjh_XaG36"
      },
      "source": [
        "## Main program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFODV1UKucNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8981e244-e7d9-4652-856b-1aa74b3c0b4e"
      },
      "source": [
        "a = (2031, 896, 2) ;  # Participant-votes data, 2 layers (pos,neg)\n",
        "maxitrtn = 1000 ;     # Nr of iterations\n",
        "flpath = \"/content/\"  # Path to data files\n",
        "latfact = 2\n",
        "np.random.seed(2320)  # Fix seed for backend comparison\n",
        "\n",
        "tl.set_backend('tensorflow') # Change backend used by TensorLy\n",
        "\n",
        "# Assembling the participant-votes tensor\n",
        "Weights = tl.tensor(np.random.choice(a=[0., 1.], size=(a[0], a[1], a[2]) ));   # 1 for observations, 0 for missing links (to be predicted)\n",
        "X = tl.tensor(np.stack([np.genfromtxt(flpath + \"participant-votes-dataonly-positive.csv\", delimiter=','),\n",
        "                        np.genfromtxt(flpath + \"participant-votes-dataonly-negative.csv\", delimiter=',')], \n",
        "                       axis=2\n",
        "                      )\n",
        "             )\n",
        "\n",
        "# resolution of CP\n",
        "A, B, C = tl.tensor(np.random.rand(a[0], latfact)), tl.tensor(np.random.rand(a[1], latfact)), tl.tensor(np.random.rand(a[2], latfact))\n",
        "#A, B, C = nncpals(X, latfact, A, B, C, Weights, maxitrtn) ;\n",
        "%lprun -f nncpals nncpals(X, latfact, A, B, C, Weights, 1000) ;  # Profiling main function"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of iterations: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ri4Y2DBLHZn"
      },
      "source": [
        "# Experiments / speedups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGrjp0eXLNbM"
      },
      "source": [
        "## Comparing naive rebuilding X from A,B,C vs specialized tensorly.cp_to_tensor command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UXv59-uFtGI"
      },
      "source": [
        "#from tensorly.decomposition import parafac\r\n",
        "#weights, factors = parafac(X, rank=2)\r\n",
        "weights = np.array([1., 1.])\r\n",
        "TL = tl.cp_to_tensor((weights,[A,B,C]))\r\n",
        "Xh = buildCP3(A,B,C)\r\n",
        "TL - Xh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPhERBRmLtVv"
      },
      "source": [
        "## Profiling errorfun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK-EDht7JF4q"
      },
      "source": [
        "weights = np.array([1., 1.])\r\n",
        "Xh = tl.cp_to_tensor((weights,[A,B,C]))\r\n",
        "%lprun -f errorfun errorfun(X,Xh)\r\n",
        "#%lprun -f tl.metrics.regression.MSE tl.metrics.regression.MSE(X,Xh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dTF5g_WsFGx"
      },
      "source": [
        "weights = np.array([1., 1.])\r\n",
        "Xh = tl.cp_to_tensor((weights,[A,B,C]))\r\n",
        "%lprun -f objfunweighted objfunweighted(X, Xh, Weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evzA-kCoLk55"
      },
      "source": [
        "## Naive check on how many participant-votes observations are predicted both positive and negative (obv a mistake)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdBV9dqTscrR"
      },
      "source": [
        "'''\n",
        "Xh = buildCP3(A, B, C) ;\n",
        "counter = 0\n",
        "for i = 1:size(Xh)[1]\n",
        "  for j = 1:size(Xh)[2]\n",
        "    if Xh[i,j,1] > 0.5 && Xh[i,j,2] < -0.5\n",
        "      counter += 1 ;\n",
        "    end\n",
        "  end\n",
        "end\n",
        "print(\"Mistakes: \")\n",
        "print(counter) ;\n",
        "print(\" out of \")\n",
        "print(size(Xh)[1] * size(Xh)[2]) ;\n",
        "println(\" (\", 100 * counter / (size(Xh)[1] * size(Xh)[2]), \"%)\") ;\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UTbiW4vIOyR"
      },
      "source": [
        "## Obsolete code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX-DWKF9tXl8"
      },
      "source": [
        "def objfunweighted(X, Xh, W):\r\n",
        "  #Z = np.multiply(X-Xh,X-Xh) ;\r\n",
        "  Z = (X-Xh) **2 \r\n",
        "  for l in range(Z.shape[2]):\r\n",
        "    Z[:,:,l] = np.multiply(Z[:,:,l], W) ;\r\n",
        "\r\n",
        "  return np.sqrt( np.sum(Z) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CCj9rfMHrFC"
      },
      "source": [
        "def objfunweighted(X, Xh, Wt):\r\n",
        "  zrs = tl.zeros_like(X)\r\n",
        "  weighted_X = tl.where(Wt == 1, X, zrs)\r\n",
        "  weighted_Xh = tl.where(Wt == 1, Xh, zrs)\r\n",
        "  \r\n",
        "  return np.sqrt(np.sum((weighted_X - weighted_Xh)**2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}